r_squared <- summary(model)$r.squared
equation_text <- sprintf("y = %.4fx + %.2f\nR² = %.2f, slope t-stat = %.2f", slope, intercept, r_squared, t_value)
binscatter = binsreg(y=temp_filtered_inc$dif, x=temp_filtered_inc$wfh_share, nbins=30, polyreg=1,
bycolors = teal, weights = temp_filtered_inc$population, vce='HC1', cluster=temp_filtered_inc$MetroShort)
data.dots <- binscatter$data.plot$`Group Full Sample`$data.dots
data.line <- binscatter$data.plot$`Group Full Sample`$data.poly
ggplot() + geom_point(data=data.dots, aes(x=x, y=fit), size=3, colour=teal) +
geom_line(data=data.line, aes(x=x, y=fit), size = 1.5, colour=teal) +
theme_bw() + labs(x="City's observed WFH share from WFH Map, 2023 avg", y="Cumulative net pop ouflow\n Mar 2022-Feb 2023") +
annotate("text", x = 20, y = 2, label = equation_text, hjust = 0, vjust = 0, size = 5) +
theme(axis.title = element_text(size = 20),
axis.text = element_text(size = 20),
panel.border = element_blank())
ggsave('./figures-tables/figs9b_donut_vs_wfhmap.png', plot = last_plot(), width = 10, height = 8)
summary_model
################################################
# Table S2: Zillow regression
################################################
## Read in rents file and run ms
df_rent <- read_csv('./data/zori_panel_zips_top12.csv') %>% filter(MetroShort %in% cities) %>%
rename(rent_pct_change = post_pct_change) %>% filter(!is.na(rent_pct_change))
df_rent
###############################################
# 5. Zillow ~ USPS
###############################################
df = read_csv('./data/zhvi_usps.csv')
#prepare binscatter
model = lm(post_pct_change ~ post_pop, weights=`2019 Population`, data = df)
summary_model = coeftest(model, vcov=vcovCL, cluster=~zip)
slope <- summary_model["post_pop", "Estimate"]
intercept <- summary_model["(Intercept)", "Estimate"]
t_value <- summary_model["post_pop", "t value"]
r_squared <- summary(model)$r.squared
equation_text <- sprintf("y = %.4fx + %.2f\nR² = %.2f, slope t-stat = %.2f", slope, intercept, r_squared, t_value)
binscatter = binsreg(y=df$post_pct_change, x=df$post_pop, nbins=30,
polyreg=1, bycolors = teal, weights = df$`2019 Population`, vce='HC1', cluster=usps_census$zip)
binscatter = binsreg(y=df$post_pct_change, x=df$post_pop, nbins=30,
polyreg=1, bycolors = teal, weights = df$`2019 Population`, vce='HC1', cluster=df$zip)
data.dots <- binscatter$data.plot$`Group Full Sample`$data.dots
data.line <- binscatter$data.plot$`Group Full Sample`$data.poly
ggplot() + labs(x="Net inflow as a percent of population", y="Percent change in home value index", size=12) +
geom_point(data=data.dots, aes(x=x, y=fit), size=3, colour=teal) +
geom_line(data=data.line, aes(x=x, y=fit), size = 1.5, colour=teal) +
theme_bw() + annotate("text", x = -5, y = 8, label = equation_text, hjust = 0, vjust = 0, size = 5) +
theme(axis.title = element_text(size = 20),
axis.text = element_text(size = 20),
panel.border = element_blank())  +
xlim(-20, 20) + ylim(5, 40)
ggsave('./figures-tables/figs10b_usps_zillow.png', plot = last_plot(), width = 10, height = 8)
###########################################
## 3. Census ~ USPS net flows
###########################################
# 1. Read in Census data
#https://www.census.gov/data/datasets/time-series/demo/popest/2010s-counties-total.html#par_textimage_70769902
#https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2010-2019/co-est2019-alldata.pdf
# data definition above show that domestic migration in 2019 covers the period 7/1/2018 to 6/30/2019
census <- read_csv('https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv') %>%
mutate(county = as.double(paste(STATE, COUNTY, sep = '')),
pop_change18 = NPOPCHG_2017 + NPOPCHG_2018,
pop_change19 = NPOPCHG_2017 + NPOPCHG_2018 + NPOPCHG_2019,
pop17 = POPESTIMATE2017,
pop18 = POPESTIMATE2018,
pop19 = POPESTIMATE2019,
pop_est_change19=pop19-pop17,
mig18 = DOMESTICMIG2018,
mig19 = DOMESTICMIG2018 + DOMESTICMIG2019,
pop_pchange18 = pop_change18/pop17,
pop_pchange19 = pop_change19/pop17,
pop_est_pchange19=pop_est_change19/pop17,
mig_pchange18 = mig18/pop17,
mig_pchange19 = mig19/pop17
) %>%
select(county, pop_change18, pop_change19, pop17, pop18, mig18, mig19, pop_pchange18, pop_pchange19,
pop_est_pchange19, mig_pchange18, mig_pchange19)
#read in zip code characteristics
chars <- read_csv('./data/zip_all_chars_cbd.csv', col_types = cols('zip' = col_integer(), 'state' = col_integer(), 'county' = col_integer())) %>%
select(zip, state, county) %>% mutate(county = state*1000 + as.integer(county))
# 2. Read in zip code level USPS flow data
usps <- read_csv('./data/USPS_zips.csv') %>%
filter(date >= as.Date('2017-07-01'), date < as.Date('2019-07-01')) %>%
group_by(zip) %>% summarise(net_pop = sum(net_pop))
#Group data to county level and compare to population data
usps_county <- usps %>% inner_join(chars, by = 'zip') %>%
group_by(county) %>% summarise(net_pop = sum(net_pop))
outflow1819 <- read_csv('https://www.irs.gov/pub/irs-soi/countyoutflow1819.csv') %>%
mutate(county1=as.integer(y1_statefips)*1000+as.integer(y1_countyfips),
county2=as.integer(y2_statefips)*1000+as.integer(y2_countyfips),
flow = n1+n2) %>%
filter(grepl('Total Migration-US', y2_countyname))
#  filter(!grepl('Total|Non-migrants|Foreign|Northeast|Midwest|South|West', y2_countyname))
inflow1819 <- read_csv('https://www.irs.gov/pub/irs-soi/countyinflow1819.csv') %>%
mutate(county1=as.integer(y1_statefips)*1000+as.integer(y1_countyfips),
county2=as.integer(y2_statefips)*1000+as.integer(y2_countyfips),
flow = n1+n2) %>%
filter(grepl('Total Migration-US', y1_countyname))
outflow1718 <- read_csv('https://www.irs.gov/pub/irs-soi/countyoutflow1718.csv') %>%
mutate(county1=as.integer(y1_statefips)*1000+as.integer(y1_countyfips),
county2=as.integer(y2_statefips)*1000+as.integer(y2_countyfips),
flow = n1+n2) %>%
filter(grepl('Total Migration-US', y2_countyname))
inflow1718 <- read_csv('https://www.irs.gov/pub/irs-soi/countyinflow1718.csv') %>%
mutate(county1=as.integer(y1_statefips)*1000+as.integer(y1_countyfips),
county2=as.integer(y2_statefips)*1000+as.integer(y2_countyfips),
flow = n1+n2) %>%
filter(grepl('Total Migration-US', y1_countyname))
usps_census = usps_county %>% inner_join(census, by = 'county') %>%
mutate(net_pop_pchange = net_pop/pop17)
net_pop_high = quantile(usps_census$net_pop, .99)
net_pop_low = quantile(usps_census$net_pop, .01)
mig19_high = quantile(usps_census$mig19, .99)
mig19_low = quantile(usps_census$mig19, .01)
usps_census = usps_census %>% filter(
net_pop < net_pop_high, net_pop > net_pop_low,
mig19 < mig19_high, mig19 > mig19_low)
#prepare binscatter
model = lm(mig19 ~ net_pop, weights=pop17, data = usps_census)
summary_model = coeftest(model, vcov=vcovCL, cluster=~county)
slope <- summary_model["net_pop", "Estimate"]
intercept <- summary_model["(Intercept)", "Estimate"]
t_value <- summary_model["net_pop", "t value"]
r_squared <- summary(model)$r.squared
equation_text <- sprintf("y = %.4fx + %.2f\nR² = %.2f, slope t-stat = %.2f", slope, intercept, r_squared, t_value)
binscatter = binsreg(y=usps_census$mig19, x=usps_census$net_pop, nbins=30,
polyreg=1, bycolors = teal, weights = usps_census$pop17, vce='HC1', cluster=usps_census$county)
data.dots <- binscatter$data.plot$`Group Full Sample`$data.dots
data.line <- binscatter$data.plot$`Group Full Sample`$data.poly
ggplot() + labs(x="Net change-of-address inflows (USPS 2017-19)", y="Net domestic in-migration\n(Census 2017-19 using IRS data)", size=12) +
geom_point(data=data.dots, aes(x=x, y=fit), size=3, colour=teal) +
geom_line(data=data.line, aes(x=x, y=fit), size = 1.5, colour=teal) +
theme_bw() + annotate("text", x = -2.5e4, y = -5, label = equation_text, hjust = 0, vjust = 0, size = 5) +
theme(axis.title = element_text(size = 20),
axis.text = element_text(size = 20),
panel.border = element_blank())
ggsave('./figures-tables/figs10a_usps_census.png', plot = last_plot(), width = 10, height = 8)
rm(list=ls())
## This function will check if a package is installed, and if not, install it
pkgTest <- function(x) {
if (!require(x, character.only = TRUE))
{
install.packages(x, dep = TRUE);
if(!require(x, character.only = TRUE)) stop("Package not found")
}
}
## These lines load the required packages
packages <- c("tidyverse", "zoo", "directlabels", "cowplot", "pracma", "binsreg",
"lubridate", "readxl", "stringr", "sandwich", "lmtest", "geosphere")
lapply(packages, pkgTest);
cities <- c('San Francisco, CA', 'New York, NY', 'Chicago, IL', 'Boston, MA',
'Los Angeles, CA', 'Washington, DC', 'Atlanta, GA', 'Miami, FL',
'Philadelphia, PA', 'Dallas, TX', 'Houston, TX', 'Phoenix, AZ')
cbd_radius = 3218.69 #2 mile cbd radius in meters
#define colors
black <- "#2E2D29"; cardinal <- "#B1040E"; teal <- "#66b2b2"; green <- "#228B22"; marmalade <- "#d16002"
orange <- "#FFAE42"; magenta <- "#8B008B"; purple <- "#800080"; blue <- "#0000FF"; red <- "#FF0000"
options(repr.plot.width=10, repr.plot.height=8)
#end date for figures
start_date = '2018-01-01'
end_date = '2023-09-01'
end_date_long = '2025-06-01'
## start and end date for for cumulations
start_period = '2017-06-01' #start period of cumulation ending in 2020-03-01 exclusive
end_period = '2022-12-01' #end period for cumulation starting in 2020-03-01 inclusive
#set to your working directory
setwd('~/Documents/donut-effect-pnas') #path to directory
###############################################
# 1. Zillow ~ USPS
###############################################
df = read_csv('./data/zhvi_usps.csv')
#prepare binscatter
model = lm(post_pct_change ~ post_pop, weights=`2019 Population`, data = df)
summary_model = coeftest(model, vcov=vcovCL, cluster=~zip)
slope <- summary_model["post_pop", "Estimate"]
intercept <- summary_model["(Intercept)", "Estimate"]
t_value <- summary_model["post_pop", "t value"]
r_squared <- summary(model)$r.squared
equation_text <- sprintf("y = %.4fx + %.2f\nR² = %.2f, slope t-stat = %.2f", slope, intercept, r_squared, t_value)
binscatter = binsreg(y=df$post_pct_change, x=df$post_pop, nbins=30,
polyreg=1, bycolors = teal, weights = df$`2019 Population`, vce='HC1', cluster=df$zip)
data.dots <- binscatter$data.plot$`Group Full Sample`$data.dots
data.line <- binscatter$data.plot$`Group Full Sample`$data.poly
ggplot() + labs(x="Net inflow as a percent of population", y="Percent change in home value index", size=12) +
geom_point(data=data.dots, aes(x=x, y=fit), size=3, colour=teal) +
geom_line(data=data.line, aes(x=x, y=fit), size = 1.5, colour=teal) +
theme_bw() + annotate("text", x = -5, y = 8, label = equation_text, hjust = 0, vjust = 0, size = 5) +
theme(axis.title = element_text(size = 20),
axis.text = element_text(size = 20),
panel.border = element_blank())  +
xlim(-20, 20) + ylim(5, 40)
ggsave('./figures-tables/robustness/usps_zillow.png', plot = last_plot(), width = 10, height = 8)
###########################################
## 2. Census ~ USPS net flows
###########################################
# 1. Read in Census data
#https://www.census.gov/data/datasets/time-series/demo/popest/2010s-counties-total.html#par_textimage_70769902
#https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2010-2019/co-est2019-alldata.pdf
# data definition above show that domestic migration in 2019 covers the period 7/1/2018 to 6/30/2019
census <- read_csv('https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv') %>%
mutate(county = as.double(paste(STATE, COUNTY, sep = '')),
pop_change18 = NPOPCHG_2017 + NPOPCHG_2018,
pop_change19 = NPOPCHG_2017 + NPOPCHG_2018 + NPOPCHG_2019,
pop17 = POPESTIMATE2017,
pop18 = POPESTIMATE2018,
pop19 = POPESTIMATE2019,
pop_est_change19=pop19-pop17,
mig18 = DOMESTICMIG2018,
mig19 = DOMESTICMIG2018 + DOMESTICMIG2019,
pop_pchange18 = pop_change18/pop17,
pop_pchange19 = pop_change19/pop17,
pop_est_pchange19=pop_est_change19/pop17,
mig_pchange18 = mig18/pop17,
mig_pchange19 = mig19/pop17
) %>%
select(county, pop_change18, pop_change19, pop17, pop18, mig18, mig19, pop_pchange18, pop_pchange19,
pop_est_pchange19, mig_pchange18, mig_pchange19)
#read in zip code characteristics
chars <- read_csv('./data/zip_all_chars_cbd.csv', col_types = cols('zip' = col_integer(), 'state' = col_integer(), 'county' = col_integer())) %>%
select(zip, state, county) %>% mutate(county = state*1000 + as.integer(county))
# 2. Read in zip code level USPS flow data
usps <- read_csv('./data/USPS_zips.csv') %>%
filter(date >= as.Date('2017-07-01'), date < as.Date('2019-07-01')) %>%
group_by(zip) %>% summarise(net_pop = sum(net_pop))
#Group data to county level and compare to population data
usps_county <- usps %>% inner_join(chars, by = 'zip') %>%
group_by(county) %>% summarise(net_pop = sum(net_pop))
outflow1819 <- read_csv('https://www.irs.gov/pub/irs-soi/countyoutflow1819.csv') %>%
mutate(county1=as.integer(y1_statefips)*1000+as.integer(y1_countyfips),
county2=as.integer(y2_statefips)*1000+as.integer(y2_countyfips),
flow = n1+n2) %>%
filter(grepl('Total Migration-US', y2_countyname))
#  filter(!grepl('Total|Non-migrants|Foreign|Northeast|Midwest|South|West', y2_countyname))
inflow1819 <- read_csv('https://www.irs.gov/pub/irs-soi/countyinflow1819.csv') %>%
mutate(county1=as.integer(y1_statefips)*1000+as.integer(y1_countyfips),
county2=as.integer(y2_statefips)*1000+as.integer(y2_countyfips),
flow = n1+n2) %>%
filter(grepl('Total Migration-US', y1_countyname))
outflow1718 <- read_csv('https://www.irs.gov/pub/irs-soi/countyoutflow1718.csv') %>%
mutate(county1=as.integer(y1_statefips)*1000+as.integer(y1_countyfips),
county2=as.integer(y2_statefips)*1000+as.integer(y2_countyfips),
flow = n1+n2) %>%
filter(grepl('Total Migration-US', y2_countyname))
inflow1718 <- read_csv('https://www.irs.gov/pub/irs-soi/countyinflow1718.csv') %>%
mutate(county1=as.integer(y1_statefips)*1000+as.integer(y1_countyfips),
county2=as.integer(y2_statefips)*1000+as.integer(y2_countyfips),
flow = n1+n2) %>%
filter(grepl('Total Migration-US', y1_countyname))
usps_census = usps_county %>% inner_join(census, by = 'county') %>%
mutate(net_pop_pchange = net_pop/pop17)
net_pop_high = quantile(usps_census$net_pop, .99)
net_pop_low = quantile(usps_census$net_pop, .01)
mig19_high = quantile(usps_census$mig19, .99)
mig19_low = quantile(usps_census$mig19, .01)
usps_census = usps_census %>% filter(
net_pop < net_pop_high, net_pop > net_pop_low,
mig19 < mig19_high, mig19 > mig19_low)
#prepare binscatter
model = lm(mig19 ~ net_pop, weights=pop17, data = usps_census)
summary_model = coeftest(model, vcov=vcovCL, cluster=~county)
slope <- summary_model["net_pop", "Estimate"]
intercept <- summary_model["(Intercept)", "Estimate"]
t_value <- summary_model["net_pop", "t value"]
r_squared <- summary(model)$r.squared
equation_text <- sprintf("y = %.4fx + %.2f\nR² = %.2f, slope t-stat = %.2f", slope, intercept, r_squared, t_value)
binscatter = binsreg(y=usps_census$mig19, x=usps_census$net_pop, nbins=30,
polyreg=1, bycolors = teal, weights = usps_census$pop17, vce='HC1', cluster=usps_census$county)
data.dots <- binscatter$data.plot$`Group Full Sample`$data.dots
data.line <- binscatter$data.plot$`Group Full Sample`$data.poly
ggplot() + labs(x="Net change-of-address inflows (USPS 2017-19)", y="Net domestic in-migration\n(Census 2017-19 using IRS data)", size=12) +
geom_point(data=data.dots, aes(x=x, y=fit), size=3, colour=teal) +
geom_line(data=data.line, aes(x=x, y=fit), size = 1.5, colour=teal) +
theme_bw() + annotate("text", x = -2.5e4, y = -5, label = equation_text, hjust = 0, vjust = 0, size = 5) +
theme(axis.title = element_text(size = 20),
axis.text = element_text(size = 20),
panel.border = element_blank())
ggsave('./figures-tables/robustness/usps_census.png', plot = last_plot(), width = 10, height = 8)
###########################################
# 3. USPS ~ Data Axle
###########################################
usps <- read_csv('./data/USPS_zips.csv') %>%
filter(date >= as.Date('2017-07-01'), date < as.Date('2019-07-01')) %>%
group_by(zip) %>% summarise(net_pop = sum(net_pop))
#Group data to county level and compare to population data
usps_county <- usps %>% inner_join(chars, by = 'zip') %>%
group_by(county) %>% summarise(net_pop = sum(net_pop))
summary_model
###########################################
# 3. USPS ~ Data Axle
###########################################
usps <- read_csv('./data/USPS_zips.csv') %>%
filter(date >= as.Date('2017-07-01'), date < as.Date('2019-07-01')) %>%
group_by(zip) %>% summarise(net_pop = sum(net_pop))
#Group data to county level and compare to population data
usps_county <- usps %>% inner_join(chars, by = 'zip') %>%
group_by(county) %>% summarise(net_pop = sum(net_pop))
usps_census_gsb = usps_county %>% inner_join(census, by = 'county') %>%
mutate(net_pop_pchange = net_pop/pop17) %>%
inner_join(gsb_net_flow, by = 'county') %>%
mutate(total_pchange = total/pop17)
total_low = quantile(usps_census_gsb$total, .01)
net_pop_high = quantile(usps_census_gsb$net_pop, .99)
net_pop_low = quantile(usps_census_gsb$net_pop, .01)
###############################################
# 3. Census ~ Data Axle
###############################################
# Calculate moves from 20170701-20190701
gsb_flows <- read_csv('./data/external_data/USPS_gsb/usps_gsb_zip_flows_2017_19.csv') %>%
mutate(ZIP_pre = as.double(ZIP_pre), ZIP_post = as.double(ZIP_post))
chars <- read_csv('./data/zip_all_chars_cbd.csv', col_types = cols('zip'=col_integer(), 'county' = col_integer(), 'state'=col_integer()))%>%
mutate(county = state*1000+as.integer(county)) %>% select(zip, county)
gsb_flows <- gsb_flows %>% inner_join(chars, by=c('ZIP_pre'='zip')) %>%
inner_join(chars, by=c('ZIP_post'='zip'), suffix=c('_pre', '_post')) %>%
group_by(county_pre, county_post) %>%
summarise(count = sum(count, na.rm = TRUE),
children = sum(children, na.rm= TRUE),
spouses = sum(spouses, na.rm=TRUE)) %>%
filter(county_pre != county_post) %>%
mutate(total = count + children+spouses)
gsb_flows %>% write_csv('./data/gsb_county_flows_2017_19_clean.csv')
gsb_inflow <- gsb_flows %>% group_by(county_post) %>% summarise(total = sum(total, na.rm = TRUE))
gsb_outflow <- gsb_flows %>% group_by(county_pre) %>% summarise(total = sum(total, na.rm = TRUE))
gsb_net_flow = gsb_inflow %>% inner_join(gsb_outflow, by = c('county_post'='county_pre'), suffix=c('_in', '_out')) %>%
mutate(total = total_in-total_out) %>%
rename(county = county_post) %>%
select(county, total)
##########Census data (IRS)###########
census <- read_csv('https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv') %>%
mutate(county = as.double(paste(STATE, COUNTY, sep = '')),
pop17 = POPESTIMATE2017,
mig19 = DOMESTICMIG2018 + DOMESTICMIG2019,
mig_pchange19 = mig19/pop17
) %>% select(county, pop17, mig19, mig_pchange19)
census_gsb <- census %>% inner_join(gsb_net_flow, by = 'county')
total_high = quantile(census_gsb$total, .99)
total_low = quantile(census_gsb$total, .01)
mig19_high = quantile(census_gsb$mig19, .99)
mig19_low = quantile(census_gsb$mig19, .01)
census_gsb = census_gsb %>% filter(
total < total_high, total > total_low,
mig19 < mig19_high, mig19 > mig19_low)
#prepare binscatter
model = lm(mig19 ~ total, weights=pop17, data = census_gsb)
summary_model = coeftest(model, vcov=vcovCL, cluster=~county)
slope <- summary_model["total", "Estimate"]
intercept <- summary_model["(Intercept)", "Estimate"]
t_value <- summary_model["total", "t value"]
r_squared <- summary(model)$r.squared
equation_text <- sprintf("y = %.4fx + %.2f\nR² = %.2f, slope t-stat = %.2f", slope, intercept, r_squared, t_value)
binscatter = binsreg(y=census_gsb$mig19, x=census_gsb$total, nbins=30,
polyreg=1, bycolors = teal, weights = census_gsb$pop17, vce='HC1', cluster=census_gsb$county)
data.dots <- binscatter$data.plot$`Group Full Sample`$data.dots
data.line <- binscatter$data.plot$`Group Full Sample`$data.poly
binscatter$bins_plot + labs(x="Net change-of-address inflows\nData Axle 2017-19", y="Net domestic in-migration\nCensus 2017-19 using IRS data", size=12) +
geom_point(data=data.dots, aes(x=x, y=fit), size=3, colour=teal) +
geom_line(data=data.line, aes(x=x, y=fit), size = 1.5, colour=teal) +
theme_bw() + annotate("text", x = 1e3, y = 0, label = equation_text, hjust = 0, vjust = 0, size = 5) +
theme(axis.title = element_text(size = 20),
axis.text = element_text(size = 20),
panel.border = element_blank()) +
xlim(-5e3, 5.5e3) + ylim(-5e3, 7e3)
ggsave('./figures-tables/robustness/census_data_axle.png', plot = last_plot(), width = 10, height = 8)
summary_model
###########################################
# 4. USPS ~ Data Axle
###########################################
usps <- read_csv('./data/USPS_zips.csv') %>%
filter(date >= as.Date('2017-07-01'), date < as.Date('2019-07-01')) %>%
group_by(zip) %>% summarise(net_pop = sum(net_pop))
#Group data to county level and compare to population data
usps_county <- usps %>% inner_join(chars, by = 'zip') %>%
group_by(county) %>% summarise(net_pop = sum(net_pop))
usps_census_gsb = usps_county %>% inner_join(census, by = 'county') %>%
mutate(net_pop_pchange = net_pop/pop17) %>%
inner_join(gsb_net_flow, by = 'county') %>%
mutate(total_pchange = total/pop17)
# First model: start with raw migration flows
total_high = quantile(usps_census_gsb$total, .99)
total_low = quantile(usps_census_gsb$total, .01)
net_pop_high = quantile(usps_census_gsb$net_pop, .99)
net_pop_low = quantile(usps_census_gsb$net_pop, .01)
usps_census_gsb = usps_census_gsb %>% filter(
total < total_high, total > total_low,
net_pop < net_pop_high, net_pop > net_pop_low)
#prepare binscatter
model = lm(net_pop ~ total, weights=pop17, data = usps_census_gsb)
summary_model = coeftest(model, vcov=vcovCL, cluster=~county)
slope <- summary_model["total", "Estimate"]
intercept <- summary_model["(Intercept)", "Estimate"]
t_value <- summary_model["total", "t value"]
r_squared <- summary(model)$r.squared
equation_text <- sprintf("y = %.4fx + %.2f\nR² = %.2f, slope t-stat = %.2f", slope, intercept, r_squared, t_value)
binscatter = binsreg(y=usps_census_gsb$net_pop, x=usps_census_gsb$total, nbins=30,
polyreg=1, bycolors = teal, weights = usps_census_gsb$pop17, vce='HC1', cluster=usps_census_gsb$county)
data.dots <- binscatter$data.plot$`Group Full Sample`$data.dots
data.line <- binscatter$data.plot$`Group Full Sample`$data.poly
binscatter$bins_plot + labs(x="Net change-of-address inflows\n(Data Axle 2017-19)", y="Net change-of-address inflows\nUSPS 2017-19", size=12) +
geom_point(data=data.dots, aes(x=x, y=fit), size=3, colour=teal) +
geom_line(data=data.line, aes(x=x, y=fit), size = 1.5, colour=teal) +
theme_bw() + annotate("text", x = 0, y = -7e3, label = equation_text, hjust = 0, vjust = 0, size = 5) +
theme(axis.title = element_text(size = 20),
axis.text = element_text(size = 20),
panel.border = element_blank()) +
xlim(-4e3, 7e3) + ylim(-1e4, 3e3)
ggsave('./figures-tables/robustness/gsb_usps.png', plot = last_plot(), width = 10, height = 8)
summary_model
ies
## Preliminaries
rm(list=ls())
## This function will check if a package is installed, and if not, install it
pkgTest <- function(x) {
if (!require(x, character.only = TRUE))
{
install.packages(x, dep = TRUE);
if(!require(x, character.only = TRUE)) stop("Package not found")
}
}
## Create function to get robust standard errors
rse <- function(reg) {
return(as.vector(summary(reg, robust = T)$coefficients[,"Std. Error"]))
}
## Create function to get clustered standard errors
cle <- function(model) {
cl_se = vcovCL(model, cluster = ~ MetroShort) #get clustered covariance matrix
return(sqrt(diag(cl_se))) #get diagonal and take square root to get std. errors
}
## These lines load the required packages
packages <- c("tidyverse",  "pracma", "lubridate", "stargazer", "sjstats",
"readxl", "stringr", "forecast", "lmtest", "sandwich")
lapply(packages, pkgTest);
cities <- c('San Francisco, CA', 'New York, NY', 'Chicago, IL', 'Boston, MA',
'Los Angeles, CA', 'Washington, DC', 'Atlanta, GA', 'Miami, FL',
'Philadelphia, PA', 'Dallas, TX', 'Houston, TX', 'Phoenix, AZ')
#set to your working directory
setwd('~/Documents/donut-effect-pnas/')
####################################
# Table S1a. Mastercard USA
####################################
df = read_csv('./data/external_data/mastercard/donut-effect-usa.csv') %>%
mutate(date = as.Date(date)) %>% filter(distance_column == '30 mile')
city_chars=read_csv('./data/us_city_chars.csv')
df = df %>% select(old_city_name, iso, date, distance_column, donut_effect_ring, donut_effect_cumulative) %>%
inner_join(city_chars, by='old_city_name') %>%
rename(city = old_city_name)
wfh = read_excel('./data/external_data/remote_work_in_job_ads_signup_data.xlsx', sheet = 'us_city_by_month') %>%
mutate(MetroShort = paste(city, state, sep = ", ")) %>%
filter(year_month >= 2023, measurement == '1 Month Average') %>%
group_by(MetroShort) %>% summarise(wfh_share = mean(percent, na.rm=TRUE)/100)
df2 = df %>% left_join(wfh, by='MetroShort')
# July 2022 to June 2023 donut index, average
df_post = df2 %>% filter(date >= as.Date("2022-10-01"), date < as.Date('2023-10-01')) %>%
group_by(MetroShort) %>% summarise(wfh_share = mean(wfh_share, na.rm=TRUE),
wfh_emp = mean(wfh_emp, na.rm=TRUE),
gdp_capita = mean(gdp_capita, na.rm=TRUE)/1000,
density2019 = mean(density2019, na.rm=TRUE)/1000,
population = mean(population, na.rm=TRUE),
donut_post = mean(donut_effect_cumulative, na.rm=TRUE))
# July 2022 to June 2023 donut index, average
df_pre = df2 %>% filter(date >= as.Date("2018-10-01"), date < as.Date('2019-10-01')) %>%
group_by(MetroShort) %>% summarise(donut_pre = mean(donut_effect_cumulative, na.rm=TRUE))
df_post = df_post %>% inner_join(df_pre, by = 'MetroShort')
m0 <- lm(donut_post ~ donut_pre + log(density2019), data = df_post, weights=df_post$population)
#m1 <- lm(donut_post ~ donut_pre + wfh_emp, data = df_post, weights=df_post$population)
m1 <- lm(donut_post ~ donut_pre + log(gdp_capita), data = df_post, weights=df_post$population)
m2 <- lm(donut_post ~ donut_pre + log(wfh_share), data = df_post, weights=df_post$population)
m3 <- lm(donut_post ~ donut_pre + log(density2019) + log(gdp_capita) + log(wfh_share), data = df_post, weights=df_post$population)
####################################
# Table S1b. Mastercard global
####################################
df = read_csv('./data/external_data/mastercard/donut-effect-main.csv') %>%
mutate(date = as.Date(date)) %>% filter(distance_column == '30 mile')
city_chars=read_csv('./data/global_city_chars.csv') %>%
#group_by(iso) %>% slice_max(order_by = population2, n = 1) %>%
select(iso, old_city_name, country, gdp_ppp_2019, population2)
df = df %>% select(old_city_name, iso, date, distance_column, donut_effect_ring, donut_effect_cumulative) %>%
inner_join(city_chars, by=c('old_city_name', 'iso')) %>%
rename(city = old_city_name)
oxf = read_csv("~/Documents/zillow/thesis/data/global-donut-mastercard/oxf_lockdown.csv") %>%
rename(country=country_name) %>% group_by(country) %>%
summarise(cumulative_lockdown = sum(lockdown_index, na.rm=TRUE))
wfh = read_excel('./data/external_data/GSWA-Figures-Data-2023.xlsx',
sheet='Figure 1', range="A1:C36") %>% rename(wfh_days = `Number of days working from home this week`) %>%
select(iso, wfh_days)
df2 = df %>% left_join(wfh, by='iso') %>% left_join(oxf, by = "country")
# July 2022 to June 2023 donut index, average
df_post = df2 %>% filter(date >= as.Date("2022-10-01"), date < as.Date('2023-10-01')) %>%
group_by(city, iso) %>% summarise(gdp_capita=mean(gdp_ppp_2019)/1000,
donut_post=mean(donut_effect_cumulative, na.rm=TRUE),
cumulative_lockdown = mean(cumulative_lockdown, na.rm = TRUE)/1000,
wfh_share = mean(wfh_days, na.rm=TRUE)/5,
population2 = mean(population2, na.rm=TRUE))
df_pre = df2 %>% filter(date >= as.Date("2018-10-01"), date < as.Date('2019-10-01')) %>%
group_by(city, iso) %>% summarise(donut_pre = mean(donut_effect_cumulative, na.rm=TRUE))
df_post = df_post %>% inner_join(df_pre, by = c('city', 'iso'))
m4 <- lm(donut_post ~ log(cumulative_lockdown), data = df_post, weights=df_post$population2)
m5 <- lm(donut_post ~ log(gdp_capita), data = df_post, weights=df_post$population2)
m6 <- lm(donut_post ~ wfh_share, data = df_post, weights=df_post$population2)
m7 <- lm(donut_post ~ log(cumulative_lockdown) + log(gdp_capita) + wfh_share, data = df_post, weights=df_post$population2)
stargazer(list(m0, m1, m2, m3, m4, m5, m6, m7),
se = list(rse(m0), rse(m1), rse(m2), rse(m3), rse(m4), rse(m5), rse(m6), rse(m7)),
omit.stat=c("adj.rsq", "ser","f"),
type="html", out="./figures-tables/tab0.doc")
m4 <- lm(donut_post ~ log(cumulative_lockdown), data = df_post, weights=df_post$population2)
m5 <- lm(donut_post ~ log(gdp_capita), data = df_post, weights=df_post$population2)
m6 <- lm(donut_post ~ log(wfh_share), data = df_post, weights=df_post$population2)
m7 <- lm(donut_post ~ log(cumulative_lockdown) + log(gdp_capita) + wfh_share, data = df_post, weights=df_post$population2)
stargazer(list(m0, m1, m2, m3, m4, m5, m6, m7),
se = list(rse(m0), rse(m1), rse(m2), rse(m3), rse(m4), rse(m5), rse(m6), rse(m7)),
omit.stat=c("adj.rsq", "ser","f"),
type="html", out="./figures-tables/tab0.doc")
m7 <- lm(donut_post ~ log(cumulative_lockdown) + log(gdp_capita) + log(wfh_share), data = df_post, weights=df_post$population2)
stargazer(list(m0, m1, m2, m3, m4, m5, m6, m7),
se = list(rse(m0), rse(m1), rse(m2), rse(m3), rse(m4), rse(m5), rse(m6), rse(m7)),
omit.stat=c("adj.rsq", "ser","f"),
type="html", out="./figures-tables/tab0.doc")
